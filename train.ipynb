{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import datetime\n",
    "import TACNN\n",
    "import sys\n",
    "\n",
    "#tf.flags.DEFINE_string(\"word2vec\", \"../data/google.bin\", \"Word2vec file with pre-trained embeddings (default: None)\")\n",
    "tf.flags.DEFINE_string(\"word2vec\", None, \"Word2vec file with pre-trained embeddings (default: None)\")\n",
    "tf.flags.DEFINE_string(\"valid_data\",\"../data/music.test\", \" Data for validation\")\n",
    "tf.flags.DEFINE_string(\"para_data\", \"../data/music.para\", \"Data parameters\")\n",
    "tf.flags.DEFINE_string(\"train_data\", \"../data/music.train\", \"Data for training\")\n",
    "tf.app.flags.DEFINE_string('f', '', 'kernel')\n",
    "\n",
    "# Model Hyperparameters\n",
    "# tf.flags.DEFINE_string(\"word2vec\", \"./data/rt-polaritydata/google.bin\", \"Word2vec file with pre-trained embeddings (default: None)\")\n",
    "#tf.flags.DEFINE_integer(\"embedding_dim\", 300, \"Dimensionality of character embedding \")\n",
    "tf.flags.DEFINE_integer(\"embedding_dim\", 50, \"Dimensionality of character embedding \")\n",
    "tf.flags.DEFINE_string(\"filter_sizes\", \"3\", \"Comma-separated filter sizes \")\n",
    "tf.flags.DEFINE_integer(\"num_filters\", 100, \"Number of filters per filter size\")\n",
    "tf.flags.DEFINE_float(\"dropout_keep_prob\", 0.5, \"Dropout keep probability \")\n",
    "tf.flags.DEFINE_float(\"l2_reg_lambda\", 0.001, \"L2 regularizaion lambda\")\n",
    "# Training parameters\n",
    "tf.flags.DEFINE_integer(\"batch_size\", 100, \"Batch Size \")\n",
    "tf.flags.DEFINE_integer(\"num_epochs\", 40, \"Number of training epochs \")\n",
    "# Misc Parameters\n",
    "tf.flags.DEFINE_boolean(\"allow_soft_placement\", True, \"Allow device soft device placement\")\n",
    "tf.flags.DEFINE_boolean(\"log_device_placement\", False, \"Log placement of ops on devices\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_step(u_batch, i_batch, uid, iid, reuid, reiid, y_batch,batch_num):\n",
    "    \"\"\"\n",
    "    A single training step\n",
    "    \"\"\"\n",
    "    feed_dict = {\n",
    "        deep.input_u: u_batch,\n",
    "        deep.input_i: i_batch,\n",
    "        deep.input_uid: uid,\n",
    "        deep.input_iid: iid,\n",
    "        deep.input_y: y_batch,\n",
    "        deep.input_reuid: reuid,\n",
    "        deep.input_reiid: reiid,\n",
    "        deep.drop0: 0.8,\n",
    "\n",
    "        deep.dropout_keep_prob: FLAGS.dropout_keep_prob\n",
    "    }\n",
    "    _, step, loss, accuracy, mae, u_a, i_a, fm = sess.run(\n",
    "        [train_op, global_step, deep.loss, deep.accuracy, deep.mae, deep.u_a, deep.i_a, deep.score],\n",
    "        feed_dict)\n",
    "    time_str = datetime.datetime.now().isoformat()\n",
    "    #print(\"{}: step {}, loss {:g}, rmse {:g},mae {:g}\".format(time_str, batch_num, loss, accuracy, mae))\n",
    "    return accuracy, mae, u_a, i_a, fm\n",
    "\n",
    "\n",
    "def dev_step(u_batch, i_batch, uid, iid, reuid, reiid, y_batch, writer=None):\n",
    "    \"\"\"\n",
    "    Evaluates model on a dev set\n",
    "\n",
    "    \"\"\"\n",
    "    feed_dict = {\n",
    "        deep.input_u: u_batch,\n",
    "        deep.input_i: i_batch,\n",
    "        deep.input_y: y_batch,\n",
    "        deep.input_uid: uid,\n",
    "        deep.input_iid: iid,\n",
    "        deep.input_reuid: reuid,\n",
    "        deep.input_reiid: reiid,\n",
    "        deep.drop0: 1.0,\n",
    "        deep.dropout_keep_prob: 1.0\n",
    "    }\n",
    "    step, loss, accuracy, mae = sess.run(\n",
    "        [global_step, deep.loss, deep.accuracy, deep.mae],\n",
    "        feed_dict)\n",
    "    time_str = datetime.datetime.now().isoformat()\n",
    "    # print(\"{}: step{}, loss {:g}, rmse {:g},mae {:g}\".format(time_str, step, loss, accuracy, mae))\n",
    "\n",
    "    return [loss, accuracy, mae]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_word2vec(vocabulary):\n",
    "    # initial matrix with random uniform\n",
    "    u = 0\n",
    "    initW = np.random.uniform(-1.0, 1.0, (len(vocabulary), FLAGS.embedding_dim))\n",
    "    # load any vectors from the word2vec\n",
    "    print(\"Load word2vec u file {}\\n\".format(FLAGS.word2vec))\n",
    "    with open(FLAGS.word2vec, \"rb\") as f:\n",
    "        header = f.readline()\n",
    "        vocab_size, layer1_size = map(int, header.split())\n",
    "        binary_len = np.dtype('float32').itemsize * layer1_size\n",
    "        for line in range(vocab_size):\n",
    "            word = []\n",
    "            while True:\n",
    "                ch = f.read(1)\n",
    "                if ch == ' ':\n",
    "                    word = ''.join(word)\n",
    "                    break\n",
    "                if ch != '\\n':\n",
    "                    word.append(ch)\n",
    "            idx = 0\n",
    "\n",
    "            if word in vocabulary:\n",
    "                u = u + 1\n",
    "                idx = vocabulary[word]\n",
    "                initW[idx] = np.fromstring(f.read(binary_len), dtype='float32')\n",
    "            else:\n",
    "                f.read(binary_len)\n",
    "    return initW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_glove(vocabulary, glove_file, vocab_size=400000):\n",
    "    \"\"\"\n",
    "    Use pre-trained GloVe embedding as alternative to word2vec.\n",
    "    Load in file with specified vocab size and dimensional embedding size.\n",
    "    If word exists in user/item vocabulary, replace the row with the values.\n",
    "    \"\"\"\n",
    "    # initial matrix with random uniform\n",
    "    u = 0\n",
    "    initW = np.random.uniform(-1.0, 1.0, (len(vocabulary), FLAGS.embedding_dim))\n",
    "    \n",
    "    print(\"Load glove u file {}\\n\".format(glove_file))\n",
    "    with open(glove_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        for i in range(vocab_size):\n",
    "            line = f.readline()\n",
    "            word_embed = line.split()\n",
    "            word = word_embed[0]\n",
    "            embed = [float(x) for x in word_embed[1:]]\n",
    "            idx = 0\n",
    "\n",
    "            if word in vocabulary:\n",
    "                u = u + 1\n",
    "                idx = vocabulary[word]\n",
    "                initW[idx] = embed\n",
    "    return initW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying GloVe: https://nlp.stanford.edu/projects/glove/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove_file = \"../data/glove.6B.50d.txt\" \n",
    "#glove_file = \"../data/glove.6B.300d.txt\" \n",
    "use_glove = True # turn on if use glove instead of word2vec\n",
    "#use_glove = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Parameters:\n",
      "ALLOW_SOFT_PLACEMENT=<absl.flags._flag.BooleanFlag object at 0x000001CD3B3415C0>\n",
      "ALSOLOGTOSTDERR=<absl.flags._flag.BooleanFlag object at 0x000001CD34BB0E10>\n",
      "BATCH_SIZE=<absl.flags._flag.Flag object at 0x000001CD3B341A90>\n",
      "DROPOUT_KEEP_PROB=<absl.flags._flag.Flag object at 0x000001CD3B28AF28>\n",
      "EMBEDDING_DIM=<absl.flags._flag.Flag object at 0x000001CD3B28AAC8>\n",
      "F=<absl.flags._flag.Flag object at 0x000001CD3B28AA20>\n",
      "FILTER_SIZES=<absl.flags._flag.Flag object at 0x000001CD3B28AC50>\n",
      "L2_REG_LAMBDA=<absl.flags._flag.Flag object at 0x000001CD3B28AE10>\n",
      "LOG_DEVICE_PLACEMENT=<absl.flags._flag.BooleanFlag object at 0x000001CD3B341748>\n",
      "LOG_DIR=<absl.flags._flag.Flag object at 0x000001CD34BB0EB8>\n",
      "LOGTOSTDERR=<absl.flags._flag.BooleanFlag object at 0x000001CD34BB0940>\n",
      "NUM_EPOCHS=<absl.flags._flag.Flag object at 0x000001CD3B3410B8>\n",
      "NUM_FILTERS=<absl.flags._flag.Flag object at 0x000001CD3B28ACC0>\n",
      "ONLY_CHECK_ARGS=<absl.flags._flag.BooleanFlag object at 0x000001CD34BB9668>\n",
      "OP_CONVERSION_FALLBACK_TO_WHILE_LOOP=<absl.flags._flag.BooleanFlag object at 0x000001CD37C0D668>\n",
      "PARA_DATA=<absl.flags._flag.Flag object at 0x000001CD343156D8>\n",
      "PDB_POST_MORTEM=<absl.flags._flag.BooleanFlag object at 0x000001CD34AF9898>\n",
      "PROFILE_FILE=<absl.flags._flag.Flag object at 0x000001CD34BB95C0>\n",
      "RUN_WITH_PDB=<absl.flags._flag.BooleanFlag object at 0x000001CD34BB0048>\n",
      "RUN_WITH_PROFILING=<absl.flags._flag.BooleanFlag object at 0x000001CD34AF9908>\n",
      "SHOWPREFIXFORINFO=<absl.flags._flag.BooleanFlag object at 0x000001CD34BB9160>\n",
      "STDERRTHRESHOLD=<absl.logging._StderrthresholdFlag object at 0x000001CD34BB9048>\n",
      "TEST_RANDOM_SEED=<absl.flags._flag.Flag object at 0x000001CD38ED7588>\n",
      "TEST_RANDOMIZE_ORDERING_SEED=<absl.flags._flag.Flag object at 0x000001CD38EDE630>\n",
      "TEST_SRCDIR=<absl.flags._flag.Flag object at 0x000001CD38ED76D8>\n",
      "TEST_TMPDIR=<absl.flags._flag.Flag object at 0x000001CD38ED78D0>\n",
      "TRAIN_DATA=<absl.flags._flag.Flag object at 0x000001CD3B28AA90>\n",
      "USE_CPROFILE_FOR_PROFILING=<absl.flags._flag.BooleanFlag object at 0x000001CD34BB95F8>\n",
      "V=<absl.logging._VerbosityFlag object at 0x000001CD34BB0F28>\n",
      "VALID_DATA=<absl.flags._flag.Flag object at 0x000001CD32E81B38>\n",
      "VERBOSITY=<absl.logging._VerbosityFlag object at 0x000001CD34BB0F28>\n",
      "WORD2VEC=<absl.flags._flag.Flag object at 0x000001CD342A70F0>\n",
      "XML_OUTPUT_FILE=<absl.flags._flag.Flag object at 0x000001CD38EDEE48>\n",
      "\n",
      "Loading data...\n",
      "num users: 27530\n",
      "num items: 10618\n",
      "11\n",
      "140\n",
      "32\n",
      "140\n",
      "WARNING:tensorflow:From E:\\tacnn\\TACNN - 副本\\model\\TACNN.py:8: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\tacnn\\TACNN - 副本\\model\\TACNN.py:17: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\tacnn\\TACNN - 副本\\model\\TACNN.py:42: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\tacnn\\TACNN - 副本\\model\\TACNN.py:55: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From E:\\tacnn\\TACNN - 副本\\model\\TACNN.py:97: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Tensor(\"attention/transpose_1:0\", shape=(?, 11, 1), dtype=float32)\n",
      "WARNING:tensorflow:From E:\\tacnn\\TACNN - 副本\\model\\TACNN.py:178: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "27530\n",
      "10618\n",
      "WARNING:tensorflow:From C:\\Users\\lenovo\\miniconda3\\envs\\tensor\\lib\\site-packages\\tensorflow_core\\python\\util\\tf_should_use.py:198: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Load glove u file ../data/glove.6B.50d.txt\n",
      "\n",
      "Load glove u file ../data/glove.6B.50d.txt\n",
      "\n",
      "ll\n",
      "1851\n",
      "\n",
      "Evaluation:\n",
      "500\n",
      "loss_valid 46.7096, rmse_valid 0.967179, mae_valid 0.670033\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1000\n",
      "loss_valid 44.8858, rmse_valid 0.948057, mae_valid 0.719722\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1500\n",
      "loss_valid 50.9593, rmse_valid 1.01013, mae_valid 0.85144\n",
      "\n",
      "0:\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "train:rmse,mae: 1.2886921790469215 1.0298515046241796\n",
      "loss_valid 44.2786, rmse_valid 0.941642, mae_valid 0.733129\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "500\n",
      "loss_valid 41.9553, rmse_valid 0.916555, mae_valid 0.669214\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1000\n",
      "loss_valid 41.3282, rmse_valid 0.909732, mae_valid 0.626566\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1500\n",
      "loss_valid 41.4447, rmse_valid 0.910996, mae_valid 0.665588\n",
      "\n",
      "1:\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "train:rmse,mae: 0.9474746375905702 0.7163561102926634\n",
      "loss_valid 41.5883, rmse_valid 0.912567, mae_valid 0.672206\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "500\n",
      "loss_valid 40.8654, rmse_valid 0.904573, mae_valid 0.626228\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1000\n",
      "loss_valid 40.8898, rmse_valid 0.904824, mae_valid 0.620855\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1500\n",
      "loss_valid 40.8281, rmse_valid 0.904036, mae_valid 0.623031\n",
      "\n",
      "2:\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "train:rmse,mae: 0.8551127743167145 0.6142811400384146\n",
      "loss_valid 41.8505, rmse_valid 0.915251, mae_valid 0.631202\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "500\n",
      "loss_valid 40.7194, rmse_valid 0.90276, mae_valid 0.618843\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1000\n",
      "loss_valid 41.1607, rmse_valid 0.907672, mae_valid 0.61628\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1500\n",
      "loss_valid 40.8458, rmse_valid 0.904133, mae_valid 0.615778\n",
      "\n",
      "3:\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "train:rmse,mae: 0.8237726618186131 0.578617635738006\n",
      "loss_valid 41.5236, rmse_valid 0.911553, mae_valid 0.622667\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "500\n",
      "loss_valid 40.9349, rmse_valid 0.905078, mae_valid 0.609555\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1000\n",
      "loss_valid 41.1143, rmse_valid 0.907072, mae_valid 0.614364\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1500\n",
      "loss_valid 41.0807, rmse_valid 0.906682, mae_valid 0.618577\n",
      "\n",
      "4:\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "train:rmse,mae: 0.8033326106545475 0.5571722794809192\n",
      "loss_valid 41.8764, rmse_valid 0.915424, mae_valid 0.622601\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "500\n",
      "loss_valid 40.8684, rmse_valid 0.904249, mae_valid 0.609917\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1000\n",
      "loss_valid 41.4705, rmse_valid 0.910895, mae_valid 0.615511\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1500\n",
      "loss_valid 41.4022, rmse_valid 0.910151, mae_valid 0.616702\n",
      "\n",
      "5:\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "train:rmse,mae: 0.7887287351455256 0.5425111402021364\n",
      "loss_valid 42.3657, rmse_valid 0.920729, mae_valid 0.626552\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "500\n",
      "loss_valid 41.2777, rmse_valid 0.90873, mae_valid 0.606188\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1000\n",
      "loss_valid 42.0213, rmse_valid 0.916889, mae_valid 0.62217\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1500\n",
      "loss_valid 41.811, rmse_valid 0.91462, mae_valid 0.619145\n",
      "\n",
      "6:\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "train:rmse,mae: 0.7765557476148807 0.5307008897466057\n",
      "loss_valid 42.6009, rmse_valid 0.923243, mae_valid 0.623024\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "500\n",
      "loss_valid 41.6841, rmse_valid 0.91314, mae_valid 0.609511\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1000\n",
      "loss_valid 42.0154, rmse_valid 0.916791, mae_valid 0.621698\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1500\n",
      "loss_valid 41.8649, rmse_valid 0.915216, mae_valid 0.617656\n",
      "\n",
      "7:\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "train:rmse,mae: 0.7623470993637073 0.5180413059805742\n",
      "loss_valid 42.7387, rmse_valid 0.924776, mae_valid 0.627705\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "500\n",
      "loss_valid 41.6784, rmse_valid 0.913079, mae_valid 0.608744\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1000\n",
      "loss_valid 42.3867, rmse_valid 0.9209, mae_valid 0.621791\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1500\n",
      "loss_valid 42.7168, rmse_valid 0.9245, mae_valid 0.618501\n",
      "\n",
      "8:\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "train:rmse,mae: 0.7478090299425223 0.5059415545739205\n",
      "loss_valid 42.7787, rmse_valid 0.925191, mae_valid 0.627537\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "500\n",
      "loss_valid 42.2502, rmse_valid 0.919409, mae_valid 0.613291\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1000\n",
      "loss_valid 42.972, rmse_valid 0.9273, mae_valid 0.627624\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1500\n",
      "loss_valid 43.0201, rmse_valid 0.927765, mae_valid 0.619381\n",
      "\n",
      "9:\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "train:rmse,mae: 0.7333238055775579 0.4941465964612286\n",
      "loss_valid 43.003, rmse_valid 0.927612, mae_valid 0.623044\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "500\n",
      "loss_valid 42.566, rmse_valid 0.922923, mae_valid 0.621125\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1000\n",
      "loss_valid 43.2701, rmse_valid 0.930545, mae_valid 0.629121\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1500\n",
      "loss_valid 42.3882, rmse_valid 0.920951, mae_valid 0.617825\n",
      "\n",
      "10:\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "train:rmse,mae: 0.7165250746801954 0.4805284825001196\n",
      "loss_valid 44.3186, rmse_valid 0.941764, mae_valid 0.637278\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "500\n",
      "loss_valid 42.6349, rmse_valid 0.923664, mae_valid 0.619384\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1000\n",
      "loss_valid 42.998, rmse_valid 0.927593, mae_valid 0.625469\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation:\n",
      "1500\n",
      "loss_valid 43.2147, rmse_valid 0.929955, mae_valid 0.628883\n",
      "\n",
      "11:\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "train:rmse,mae: 0.6934168977166819 0.4646484740581595\n",
      "loss_valid 44.6239, rmse_valid 0.944993, mae_valid 0.638995\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "500\n",
      "loss_valid 43.0357, rmse_valid 0.928054, mae_valid 0.628358\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1000\n",
      "loss_valid 43.6358, rmse_valid 0.93457, mae_valid 0.635278\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1500\n",
      "loss_valid 43.4686, rmse_valid 0.932748, mae_valid 0.62994\n",
      "\n",
      "12:\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "train:rmse,mae: 0.6722215688241487 0.44953602025922346\n",
      "loss_valid 45.1239, rmse_valid 0.950384, mae_valid 0.639789\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "500\n",
      "loss_valid 43.6336, rmse_valid 0.934584, mae_valid 0.633422\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1000\n",
      "loss_valid 44.1888, rmse_valid 0.940484, mae_valid 0.638727\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1500\n",
      "loss_valid 44.064, rmse_valid 0.93917, mae_valid 0.637752\n",
      "\n",
      "13:\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "train:rmse,mae: 0.6504647562563065 0.4366222191571803\n",
      "loss_valid 45.594, rmse_valid 0.955395, mae_valid 0.645529\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "500\n",
      "loss_valid 43.8522, rmse_valid 0.936903, mae_valid 0.634911\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1000\n",
      "loss_valid 44.2469, rmse_valid 0.941071, mae_valid 0.640521\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1500\n",
      "loss_valid 44.5935, rmse_valid 0.944818, mae_valid 0.644709\n",
      "\n",
      "14:\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "train:rmse,mae: 0.629515938489003 0.4229547209285002\n",
      "loss_valid 45.6798, rmse_valid 0.956324, mae_valid 0.643814\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "500\n",
      "loss_valid 44.1297, rmse_valid 0.939864, mae_valid 0.638296\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1000\n",
      "loss_valid 45.1448, rmse_valid 0.950701, mae_valid 0.644767\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1500\n",
      "loss_valid 44.7598, rmse_valid 0.946638, mae_valid 0.646276\n",
      "\n",
      "15:\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "train:rmse,mae: 0.6110214712747298 0.4114160604215454\n",
      "loss_valid 44.8901, rmse_valid 0.948038, mae_valid 0.642282\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "500\n",
      "loss_valid 44.7604, rmse_valid 0.946646, mae_valid 0.640208\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1000\n",
      "loss_valid 44.6185, rmse_valid 0.945089, mae_valid 0.643941\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1500\n",
      "loss_valid 44.9701, rmse_valid 0.948892, mae_valid 0.644696\n",
      "\n",
      "16:\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "train:rmse,mae: 0.5951384470663735 0.4007348694201098\n",
      "loss_valid 45.0106, rmse_valid 0.949321, mae_valid 0.643523\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "500\n",
      "loss_valid 44.9057, rmse_valid 0.948224, mae_valid 0.643845\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1000\n",
      "loss_valid 45.3571, rmse_valid 0.952965, mae_valid 0.648308\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1500\n",
      "loss_valid 45.0079, rmse_valid 0.949342, mae_valid 0.649253\n",
      "\n",
      "17:\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "train:rmse,mae: 0.5801856097081493 0.39164960075236216\n",
      "loss_valid 44.7651, rmse_valid 0.94679, mae_valid 0.644362\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "500\n",
      "loss_valid 45.189, rmse_valid 0.951267, mae_valid 0.646021\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1000\n",
      "loss_valid 44.5631, rmse_valid 0.944707, mae_valid 0.641577\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1500\n",
      "loss_valid 45.0816, rmse_valid 0.950179, mae_valid 0.647496\n",
      "\n",
      "18:\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "train:rmse,mae: 0.5666443805382871 0.3832377956919513\n",
      "loss_valid 44.5619, rmse_valid 0.94468, mae_valid 0.641478\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "500\n",
      "loss_valid 44.8489, rmse_valid 0.94773, mae_valid 0.64552\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1000\n",
      "loss_valid 44.9218, rmse_valid 0.948561, mae_valid 0.644923\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1500\n",
      "loss_valid 45.5225, rmse_valid 0.954882, mae_valid 0.648989\n",
      "\n",
      "19:\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "train:rmse,mae: 0.5522949770938249 0.37481821694289075\n",
      "loss_valid 44.8607, rmse_valid 0.947933, mae_valid 0.644386\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "500\n",
      "loss_valid 45.4095, rmse_valid 0.953654, mae_valid 0.646754\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1000\n",
      "loss_valid 45.0064, rmse_valid 0.949495, mae_valid 0.647684\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1500\n",
      "loss_valid 45.5988, rmse_valid 0.955702, mae_valid 0.649785\n",
      "\n",
      "20:\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "train:rmse,mae: 0.5425770083580193 0.3682620799071334\n",
      "loss_valid 44.9793, rmse_valid 0.949156, mae_valid 0.645294\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "500\n",
      "loss_valid 45.4331, rmse_valid 0.95395, mae_valid 0.645538\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1000\n",
      "loss_valid 45.3549, rmse_valid 0.953201, mae_valid 0.649214\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1500\n",
      "loss_valid 45.8198, rmse_valid 0.958109, mae_valid 0.648618\n",
      "\n",
      "21:\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "train:rmse,mae: 0.531506095832261 0.36152719071528383\n",
      "loss_valid 45.1246, rmse_valid 0.950807, mae_valid 0.644475\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "500\n",
      "loss_valid 45.5794, rmse_valid 0.955577, mae_valid 0.645601\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1000\n",
      "loss_valid 45.5623, rmse_valid 0.955477, mae_valid 0.647152\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1500\n",
      "loss_valid 45.6017, rmse_valid 0.955844, mae_valid 0.647631\n",
      "\n",
      "22:\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "train:rmse,mae: 0.5224641749080873 0.35595025576204303\n",
      "loss_valid 45.1666, rmse_valid 0.951289, mae_valid 0.643727\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "500\n",
      "loss_valid 45.4113, rmse_valid 0.953855, mae_valid 0.644739\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1000\n",
      "loss_valid 45.6531, rmse_valid 0.956515, mae_valid 0.647183\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1500\n",
      "loss_valid 45.6095, rmse_valid 0.956051, mae_valid 0.646117\n",
      "\n",
      "23:\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "train:rmse,mae: 0.5136183568234703 0.3499097909591186\n",
      "loss_valid 45.4493, rmse_valid 0.954355, mae_valid 0.646024\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "500\n",
      "loss_valid 45.5982, rmse_valid 0.95593, mae_valid 0.645549\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1000\n",
      "loss_valid 45.8281, rmse_valid 0.95835, mae_valid 0.651946\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1500\n",
      "loss_valid 45.9128, rmse_valid 0.959173, mae_valid 0.647032\n",
      "\n",
      "24:\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "train:rmse,mae: 0.507544227125579 0.3458560249938764\n",
      "loss_valid 45.3951, rmse_valid 0.95375, mae_valid 0.643287\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "500\n",
      "loss_valid 45.7403, rmse_valid 0.957386, mae_valid 0.643556\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1000\n",
      "loss_valid 45.6366, rmse_valid 0.956321, mae_valid 0.649038\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1500\n",
      "loss_valid 45.7813, rmse_valid 0.957756, mae_valid 0.64773\n",
      "\n",
      "25:\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "train:rmse,mae: 0.49826016919088645 0.3403171240108068\n",
      "loss_valid 45.5025, rmse_valid 0.954892, mae_valid 0.642899\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "500\n",
      "loss_valid 45.9363, rmse_valid 0.959462, mae_valid 0.645378\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1000\n",
      "loss_valid 45.8887, rmse_valid 0.959028, mae_valid 0.649265\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1500\n",
      "loss_valid 45.9532, rmse_valid 0.959639, mae_valid 0.646843\n",
      "\n",
      "26:\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "train:rmse,mae: 0.49479664916093125 0.3377817431328942\n",
      "loss_valid 45.5183, rmse_valid 0.955094, mae_valid 0.644205\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "500\n",
      "loss_valid 45.4844, rmse_valid 0.95476, mae_valid 0.641483\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1000\n",
      "loss_valid 45.6031, rmse_valid 0.956098, mae_valid 0.648062\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1500\n",
      "loss_valid 45.8054, rmse_valid 0.958154, mae_valid 0.644581\n",
      "\n",
      "27:\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "train:rmse,mae: 0.4883535739088754 0.3343033749612198\n",
      "loss_valid 45.2172, rmse_valid 0.951964, mae_valid 0.640065\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "500\n",
      "loss_valid 45.3892, rmse_valid 0.953784, mae_valid 0.64154\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1000\n",
      "loss_valid 45.5661, rmse_valid 0.95573, mae_valid 0.645807\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1500\n",
      "loss_valid 45.6939, rmse_valid 0.956989, mae_valid 0.642187\n",
      "\n",
      "28:\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "train:rmse,mae: 0.48451602682753037 0.3309195005671518\n",
      "loss_valid 45.1562, rmse_valid 0.951335, mae_valid 0.639122\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "500\n",
      "loss_valid 45.3535, rmse_valid 0.953468, mae_valid 0.639935\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1000\n",
      "loss_valid 45.7679, rmse_valid 0.957894, mae_valid 0.644278\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1500\n",
      "loss_valid 45.6711, rmse_valid 0.956806, mae_valid 0.641778\n",
      "\n",
      "29:\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "train:rmse,mae: 0.4801332679617927 0.3275766335810152\n",
      "loss_valid 45.3187, rmse_valid 0.953105, mae_valid 0.63972\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "500\n",
      "loss_valid 45.5902, rmse_valid 0.955949, mae_valid 0.639596\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1000\n",
      "loss_valid 45.63, rmse_valid 0.956438, mae_valid 0.643279\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1500\n",
      "loss_valid 45.8615, rmse_valid 0.958761, mae_valid 0.643272\n",
      "\n",
      "30:\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "train:rmse,mae: 0.47591649904758593 0.3249698982713417\n",
      "loss_valid 45.3355, rmse_valid 0.953207, mae_valid 0.639754\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "500\n",
      "loss_valid 45.8741, rmse_valid 0.958908, mae_valid 0.643488\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1000\n",
      "loss_valid 46.1116, rmse_valid 0.961424, mae_valid 0.648818\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1500\n",
      "loss_valid 45.9527, rmse_valid 0.959713, mae_valid 0.645189\n",
      "\n",
      "31:\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "train:rmse,mae: 0.4722158733024783 0.3222028833589059\n",
      "loss_valid 45.6344, rmse_valid 0.956374, mae_valid 0.641251\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "500\n",
      "loss_valid 45.8932, rmse_valid 0.959052, mae_valid 0.640332\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1000\n",
      "loss_valid 46.2679, rmse_valid 0.963025, mae_valid 0.648362\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1500\n",
      "loss_valid 46.5389, rmse_valid 0.965784, mae_valid 0.646021\n",
      "\n",
      "32:\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "train:rmse,mae: 0.4676624674496942 0.31942585915697386\n",
      "loss_valid 45.8802, rmse_valid 0.958941, mae_valid 0.642668\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "500\n",
      "loss_valid 46.1622, rmse_valid 0.961897, mae_valid 0.643505\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1000\n",
      "loss_valid 46.3556, rmse_valid 0.963964, mae_valid 0.65175\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1500\n",
      "loss_valid 46.1279, rmse_valid 0.961565, mae_valid 0.646147\n",
      "\n",
      "33:\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "train:rmse,mae: 0.46644549529852575 0.3173697829439729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_valid 45.9917, rmse_valid 0.960162, mae_valid 0.643706\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "500\n",
      "loss_valid 46.0001, rmse_valid 0.960249, mae_valid 0.641929\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1000\n",
      "loss_valid 46.287, rmse_valid 0.96331, mae_valid 0.647499\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1500\n",
      "loss_valid 46.2362, rmse_valid 0.962741, mae_valid 0.647082\n",
      "\n",
      "34:\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "train:rmse,mae: 0.4617351577579492 0.3157571087586822\n",
      "loss_valid 45.8522, rmse_valid 0.95868, mae_valid 0.643168\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "500\n",
      "loss_valid 46.1655, rmse_valid 0.961922, mae_valid 0.640848\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1000\n",
      "loss_valid 46.4229, rmse_valid 0.96469, mae_valid 0.647308\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1500\n",
      "loss_valid 46.1693, rmse_valid 0.962006, mae_valid 0.643422\n",
      "\n",
      "35:\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "train:rmse,mae: 0.45934775355762564 0.31387140759257354\n",
      "loss_valid 45.9035, rmse_valid 0.959217, mae_valid 0.639247\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "500\n",
      "loss_valid 45.9975, rmse_valid 0.960228, mae_valid 0.642255\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1000\n",
      "loss_valid 45.9301, rmse_valid 0.959579, mae_valid 0.6439\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1500\n",
      "loss_valid 46.1776, rmse_valid 0.962155, mae_valid 0.643836\n",
      "\n",
      "36:\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "train:rmse,mae: 0.4594047933188984 0.31324310672405536\n",
      "loss_valid 45.8497, rmse_valid 0.958671, mae_valid 0.639759\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "500\n",
      "loss_valid 45.9793, rmse_valid 0.960029, mae_valid 0.642684\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1000\n",
      "loss_valid 46.2195, rmse_valid 0.962564, mae_valid 0.646692\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1500\n",
      "loss_valid 46.1565, rmse_valid 0.961903, mae_valid 0.645153\n",
      "\n",
      "37:\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "train:rmse,mae: 0.4543099685947938 0.30989402147771733\n",
      "loss_valid 45.9377, rmse_valid 0.959593, mae_valid 0.640332\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "500\n",
      "loss_valid 46.1975, rmse_valid 0.962328, mae_valid 0.642037\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1000\n",
      "loss_valid 46.3102, rmse_valid 0.963535, mae_valid 0.64838\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1500\n",
      "loss_valid 46.1435, rmse_valid 0.961757, mae_valid 0.644367\n",
      "\n",
      "38:\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "train:rmse,mae: 0.4507395522714241 0.3079684960607063\n",
      "loss_valid 45.7221, rmse_valid 0.957318, mae_valid 0.638245\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "500\n",
      "loss_valid 45.9206, rmse_valid 0.95944, mae_valid 0.641451\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1000\n",
      "loss_valid 46.0094, rmse_valid 0.960413, mae_valid 0.642418\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "1500\n",
      "loss_valid 46.2021, rmse_valid 0.962396, mae_valid 0.643102\n",
      "\n",
      "39:\n",
      "\n",
      "\n",
      "Evaluation:\n",
      "train:rmse,mae: 0.4510754103727562 0.30734438469672704\n",
      "loss_valid 46.0356, rmse_valid 0.960625, mae_valid 0.640277\n",
      "\n",
      "best rmse: 0.9027603423815552\n",
      "best mae: 0.6061879198889862\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    FLAGS = tf.flags.FLAGS\n",
    "    FLAGS(sys.argv)\n",
    "    print(\"\\nParameters:\")\n",
    "    for attr, value in sorted(FLAGS.__flags.items()):\n",
    "        print(\"{}={}\".format(attr.upper(), value))\n",
    "    print(\"\")\n",
    "\n",
    "    print(\"Loading data...\")\n",
    "    pkl_file = open(FLAGS.para_data, 'rb')\n",
    "\n",
    "    para = pickle.load(pkl_file)\n",
    "    user_num = para['user_num']\n",
    "    item_num = para['item_num']\n",
    "    review_num_u = para['review_num_u']\n",
    "    review_num_i = para['review_num_i']\n",
    "    review_len_u = para['review_len_u']\n",
    "    review_len_i = para['review_len_i']\n",
    "    vocabulary_user = para['user_vocab']\n",
    "    vocabulary_item = para['item_vocab']\n",
    "    train_length = para['train_length']\n",
    "    test_length = para['test_length']\n",
    "    u_text = para['u_text']\n",
    "    i_text = para['i_text']\n",
    "#     item_review = para['item_text']\n",
    "\n",
    "    np.random.seed(2020)\n",
    "    random_seed = 2020\n",
    "    print(\"num users: \" + str(user_num))\n",
    "    print(\"num items: \" + str(item_num))\n",
    "    print(review_num_u)\n",
    "    print(review_len_u)\n",
    "    print(review_num_i)\n",
    "    print(review_len_i)\n",
    "    \n",
    "    with tf.Graph().as_default():\n",
    "\n",
    "        session_conf = tf.ConfigProto(\n",
    "            allow_soft_placement=FLAGS.allow_soft_placement,\n",
    "            log_device_placement=FLAGS.log_device_placement)\n",
    "        session_conf.gpu_options.allow_growth = True\n",
    "        sess = tf.Session(config=session_conf)\n",
    "        with sess.as_default():\n",
    "            deep = TACNN.TACNN(\n",
    "                review_num_u=review_num_u,\n",
    "                review_num_i=review_num_i,\n",
    "                review_len_u=review_len_u,\n",
    "                review_len_i=review_len_i,\n",
    "                user_num=user_num,\n",
    "                item_num=item_num,\n",
    "                num_classes=1,\n",
    "                user_vocab_size=len(vocabulary_user),\n",
    "                item_vocab_size=len(vocabulary_item),\n",
    "                embedding_size=FLAGS.embedding_dim,\n",
    "                embedding_id=32,\n",
    "                filter_sizes=list(map(int, FLAGS.filter_sizes.split(\",\"))),\n",
    "                num_filters=FLAGS.num_filters,\n",
    "                l2_reg_lambda=FLAGS.l2_reg_lambda,\n",
    "                attention_size=32,\n",
    "                n_latent=32)\n",
    "            tf.set_random_seed(random_seed)\n",
    "            print (user_num)\n",
    "            print (item_num)\n",
    "            global_step = tf.Variable(0, name=\"global_step\", trainable=False)\n",
    "\n",
    "            # optimizer = tf.train.AdagradOptimizer(learning_rate=0.01, initial_accumulator_value=1e-8).minimize(deep.loss)\n",
    "            optimizer = tf.train.AdamOptimizer(0.002, beta1=0.9, beta2=0.999, epsilon=1e-8).minimize(deep.loss)\n",
    "            \n",
    "            train_op = optimizer  # .apply_gradients(grads_and_vars, global_step=global_step)\n",
    "\n",
    "\n",
    "            sess.run(tf.initialize_all_variables())\n",
    "\n",
    "            saver = tf.train.Saver()\n",
    "\n",
    "            if FLAGS.word2vec:\n",
    "                initW = extract_word2vec(vocabulary_user) # extract for user vocab\n",
    "                sess.run(deep.W1.assign(initW))\n",
    "                \n",
    "                initW = extract_word2vec(vocabulary_item) # extract for item vocab\n",
    "                sess.run(deep.W2.assign(initW))\n",
    "                # word2vec code\n",
    "                \n",
    "            elif use_glove:\n",
    "                initW = extract_glove(vocabulary_user, glove_file)\n",
    "                sess.run(deep.W1.assign(initW))\n",
    "                \n",
    "                initW = extract_glove(vocabulary_item, glove_file)\n",
    "                sess.run(deep.W2.assign(initW))\n",
    "\n",
    "            epoch = 1\n",
    "            best_mae = 5\n",
    "            best_rmse = 5\n",
    "            train_mae = 0\n",
    "            train_rmse = 0\n",
    "\n",
    "            pkl_file = open(FLAGS.train_data, 'rb')\n",
    "\n",
    "            train_data = pickle.load(pkl_file)\n",
    "\n",
    "            train_data = np.array(train_data)\n",
    "            pkl_file.close()\n",
    "\n",
    "            pkl_file = open(FLAGS.valid_data, 'rb')\n",
    "\n",
    "            test_data = pickle.load(pkl_file)\n",
    "            test_data = np.array(test_data)\n",
    "            pkl_file.close()\n",
    "\n",
    "            data_size_train = len(train_data)\n",
    "            data_size_test = len(test_data)\n",
    "            batch_size = FLAGS.batch_size\n",
    "            ll = int(len(train_data) / batch_size)\n",
    "            print('ll')\n",
    "            print(ll)\n",
    "            for epoch in range(num_epochs):\n",
    "                # Shuffle the data at each epoch\n",
    "                shuffle_indices = np.random.permutation(np.arange(data_size_train))\n",
    "                #shuffled_data = train_data[shuffle_indices]\n",
    "                shuffled_data = train_data\n",
    "                for batch_num in range(ll):\n",
    "\n",
    "                    start_index = batch_num * batch_size\n",
    "                    end_index = min((batch_num + 1) * batch_size, data_size_train)\n",
    "                    data_train = shuffled_data[start_index:end_index]\n",
    "\n",
    "                    uid, iid, reuid, reiid, y_batch = zip(*data_train)\n",
    "                    u_batch = []\n",
    "                    i_batch = []\n",
    "                    item_id = np.zeros(100)\n",
    "                    for i in range(len(uid)):\n",
    "                        u_batch.append(u_text[uid[i][0]])\n",
    "                        i_batch.append(i_text[iid[i][0]])\n",
    "                        item_id[i] = iid[i]\n",
    "                    u_batch = np.array(u_batch)\n",
    "                    i_batch = np.array(i_batch)\n",
    "\n",
    "                    t_rmse, t_mae, u_a, i_a, fm = train_step(u_batch, i_batch, uid, iid, reuid, reiid, y_batch,batch_num)\n",
    "                    i_attention = np.zeros((100,16))\n",
    "                    i_attention = i_a\n",
    "                    current_step = tf.train.global_step(sess, global_step)\n",
    "                    train_rmse += t_rmse\n",
    "                    train_mae += t_mae\n",
    "                    if batch_num % 500 == 0 and batch_num > 1:\n",
    "                        print(\"\\nEvaluation:\")\n",
    "                        print (batch_num)\n",
    "\n",
    "                        loss_s = 0\n",
    "                        accuracy_s = 0\n",
    "                        mae_s = 0\n",
    "\n",
    "                        ll_test = int(len(test_data) / batch_size) + 1\n",
    "                        for batch_num in range(ll_test):\n",
    "                            start_index = batch_num * batch_size\n",
    "                            end_index = min((batch_num + 1) * batch_size, data_size_test)\n",
    "                            data_test = test_data[start_index:end_index]\n",
    "\n",
    "                            userid_valid, itemid_valid, reuid, reiid, y_valid = zip(*data_test)\n",
    "                            u_valid = []\n",
    "                            i_valid = []\n",
    "                            for i in range(len(userid_valid)):\n",
    "                                u_valid.append(u_text[userid_valid[i][0]])\n",
    "                                i_valid.append(i_text[itemid_valid[i][0]])\n",
    "                            u_valid = np.array(u_valid)\n",
    "                            i_valid = np.array(i_valid)\n",
    "\n",
    "                            loss, accuracy, mae = dev_step(u_valid, i_valid, userid_valid, itemid_valid, reuid, reiid,\n",
    "                                                           y_valid)\n",
    "                            loss_s = loss_s + len(u_valid) * loss\n",
    "                            accuracy_s = accuracy_s + len(u_valid) * np.square(accuracy)\n",
    "                            mae_s = mae_s + len(u_valid) * mae\n",
    "                        print (\"loss_valid {:g}, rmse_valid {:g}, mae_valid {:g}\".format(loss_s / test_length,\n",
    "                                                                                         np.sqrt(\n",
    "                                                                                             accuracy_s / test_length),\n",
    "                                                                                         mae_s / test_length))\n",
    "                        rmse = np.sqrt(accuracy_s / test_length)\n",
    "                        mae = mae_s / test_length\n",
    "                        if best_rmse > rmse:\n",
    "                            best_rmse = rmse\n",
    "                        if best_mae > mae:\n",
    "                            best_mae = mae\n",
    "                        print(\"\")\n",
    "\n",
    "                print(str(epoch) + ':\\n')\n",
    "                print(\"\\nEvaluation:\")\n",
    "                print (\"train:rmse,mae:\", train_rmse / ll, train_mae / ll)\n",
    "                u_a = np.reshape(u_a[0], (1, -1))\n",
    "                i_a = np.reshape(i_a[0], (1, -1))\n",
    "\n",
    "                train_rmse = 0\n",
    "                train_mae = 0\n",
    "\n",
    "                loss_s = 0\n",
    "                accuracy_s = 0\n",
    "                mae_s = 0\n",
    "\n",
    "                ll_test = int(len(test_data) / batch_size) + 1\n",
    "                for batch_num in range(ll_test):\n",
    "                    start_index = batch_num * batch_size\n",
    "                    end_index = min((batch_num + 1) * batch_size, data_size_test)\n",
    "                    data_test = test_data[start_index:end_index]\n",
    "\n",
    "                    userid_valid, itemid_valid, reuid, reiid, y_valid = zip(*data_test)\n",
    "                    u_valid = []\n",
    "                    i_valid = []\n",
    "                    for i in range(len(userid_valid)):\n",
    "                        u_valid.append(u_text[userid_valid[i][0]])\n",
    "                        i_valid.append(i_text[itemid_valid[i][0]])\n",
    "                    u_valid = np.array(u_valid)\n",
    "                    i_valid = np.array(i_valid)\n",
    "\n",
    "                    loss, accuracy, mae = dev_step(u_valid, i_valid, userid_valid, itemid_valid, reuid, reiid, y_valid)\n",
    "                    loss_s = loss_s + len(u_valid) * loss\n",
    "                    accuracy_s = accuracy_s + len(u_valid) * np.square(accuracy)\n",
    "                    mae_s = mae_s + len(u_valid) * mae\n",
    "                print (\"loss_valid {:g}, rmse_valid {:g}, mae_valid {:g}\".format(loss_s / test_length,\n",
    "                                                                                 np.sqrt(accuracy_s / test_length),\n",
    "                                                                                 mae_s / test_length))\n",
    "                rmse = np.sqrt(accuracy_s / test_length)\n",
    "                mae = mae_s / test_length\n",
    "                if best_rmse > rmse:\n",
    "                    best_rmse = rmse\n",
    "                if best_mae > mae:\n",
    "                    best_mae = mae\n",
    "                print(\"\")\n",
    "            print ('best rmse:', best_rmse)\n",
    "            print ('best mae:', best_mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best RMSE using TACNN is 0.9027603423815552.\n",
      "The best MAE using TACNN is 0.6061879198889862.\n"
     ]
    }
   ],
   "source": [
    "print(\"The best RMSE using TACNN is {}.\" .format(best_rmse))\n",
    "print(\"The best MAE using TACNN is {}.\" .format(best_mae))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
